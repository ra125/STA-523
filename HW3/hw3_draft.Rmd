---
title: "hw3_draft"
author: "Radhika Anand, Sophie Lee, Minjung Park, Kungang Zhang"
date: "10/12/2014"
output: html_document
---



```{r}
###### Task 1  (Geocoding)
setwd("~/Team6/HW3")

#Load necessary packages
source("check_packages.R")
check_packages(c("data.table","rgeos","ggmap","rgdal","maptools", "dplyr","stringr","lubridate"))

#Load the Biggish NYC parking violations datafile
park = fread("/home/vis/cr173/Sta523/data/parking/NYParkingViolations.csv",sep=",")

#Rename required columns
setnames(park, "Violation Precinct", "Violation.Precinct")
setnames(park, "House Number", "House.Number")
setnames(park, "Street Name", "Street.Name")


#Extract the necessary variables
addr = filter(park, Violation.Precinct <= 34) %>%
       mutate(House.Number = str_trim(House.Number), Street.Name = str_trim(Street.Name)) %>%
       filter(House.Number != "" & Street.Name != "") %>%
       filter(str_detect(House.Number,"[0-9]+")) %>%
       transmute(Violation.Precinct = Violation.Precinct, addr = paste(House.Number, Street.Name)) %>%
       mutate(addr = tolower(addr))

#rm(park)


#Load 'pluto' data to geocode
basepath<-getwd()
setwd("/home/vis/cr173/Sta523/data/parking/pluto/Manhattan/")
pluto<-readShapeSpatial("MNMapPLUTO")
#pluto<-pluto_shape@data [WHY????]

setwd(basepath)
rm(basepath)

# Get rid of the observations that are not associated with Manhattan precincts [think whether to do or not!!!!!][Prof has deleted the column precinct from pluto altogether]
#pluto<-pluto[which(pluto$PolicePrct<35 & pluto$PolicePrct>0),]
#length(table(pluto$PolicePrct))

tax = cbind(data.frame(coordinates(pluto)), tolower(as.character(pluto$Address)))

names(tax)[3] = "addr"

# plot(pluto, axes=TRUE)  ### If you wanna see what the data looks like..
#pluto1<-data.frame("address"=pluto$Address, 
#                    "precinct"=pluto$PolicePrct, 
#                    coordinates(pluto)) 

#make the data content consistent, the current two targets are addr$addr and pluto$Address
#pluto$Address<-tolower(pluto$Address) #pluto address lowercases
#addraddr<-addr$addr #address of violation

#from full name to simplified version, becasue this make str_replace_all much easier
namemap<-rbind(c("east","west","street","avenue","av","avee","road","drive","terrace"," terr","bway","1st","2nd","3rd","th "), c("e","w","st","ave","ave","ave","rd","dr","ter"," ter","brdway","1","2","3"," "))
lnm<-ncol(namemap)

for (i in 1:lnm)
{
  tax$addr<-str_replace_all(tax$addr, namemap[1,i], namemap[2,i])
  addr$addr<-str_replace_all(addr$addr, namemap[1,i], namemap[2,i])
}

#some house number has 0 at the beginning, the total number is about 1100

hnvset<-str_detect(park$House.Number, "^0+([[:alnum:]]+)")
hnpset<-str_detect(tax$addr, "^0+([[:alnum:]]+)")

addrset<-str_detect(addr$addr, "^0+([[:alnum:]]+)")
addrmat<-str_match(addr$addr[addrset], "^0+([[:alnum:]]+)")
nset<-length(addrset)
seqn<-c(1:nset)
seqnmark<-seqn[addrset]#record the seq number of element detecting the pattern with first 0
nseqnmark<-length(seqnmark)#nseqmark is 1109

for(i in 1:nseqnmark)
{
  addr$addr[seqnmark[i]]<-str_replace(addr$addr[seqnmark[i]], addrmat[i,1], addrmat[i,2])
}
addrset1<-str_detect(addr$addr, "^0+([[:alnum:]]+)")

#However this part only increase ~100 data points in the final z

#after cleaning 1st, 2nd, 3rd, and ~th, the matching goes up to 1569809
#after delete first 0 in house number, the matching goes up to 1569912

#unique addr$addr
univaddr<-unique(addr$addr)
length(addr$addr)
length(univaddr)
#unique z$addr
unizaddr<-unique(z$addr)
length(unizaddr)

#not.match<-anti_join(addr$addr,z$addr)
#don't work: Error in UseMethod("anti_join") : 
#no applicable method for 'anti_join' applied to an object of class "character"

#not.mav<-anti_join(addr,tax)
not.map<-anti_join(tax,addr) #The addr only appear in tax
taxdt<-as.data.table(tax) #need to convert tax into data.table, otherwise would report error
not.mav<-anti_join(addr,taxdt) #The addr only appear in addr

uni.not.mav<-unique(not.mav)
uni.not.map<-unique(not.map)

#By inspecting data in not.map and not.mav, using format below, we can find how many data can be changed with each modification
#If the number to increase the valid data is small, then it is not worthy to loop over all of data once
test<-str_detect(addr$addr, " terr")
test[is.na(test)]<-F
sum(test) #249

test<-str_detect(addr$addr, " square$")
test[is.na(test)]<-F
sum(test) #821

test<-str_detect(tax$addr, " square")
test[is.na(test)]<-F
sum(test) #92

test<-str_detect(addr$addr, " sq$")
test[is.na(test)]<-F
sum(test) #4940

test<-str_detect(tax$addr, " sq")
test[is.na(test)]<-F
sum(test) #93

#apply(addr$addr[addrset], func)
#
#addrtry<-lapply(addr$addr[addrset], function(x) {strs<-str_match(x,"0+([[:alnum:]]+)")
#                                         str_replace_all(x,strs[1],strs[2])})

# Create a dataframe to join with the original parking dataframe
#tax = cbind(data.frame(coordinates(pluto)), tolower(as.character(pluto$Address)))
#should use converted pluto address




# Join the dataframe
#z = inner_join(addr, tax) [ASK WHY it simply crashes????????]
z = inner_join(tax,addr)

plot(z$X1,z$X2,col=z$Violation.Precinct)



######## Subsetting -- We will use 95% of the datapoints of each precinct
# pre=table(z$Violation.Precinct)
# length(pre)
# 
# q_lon<-matrix(quantile(z$X1, probs=c(0.05, 0.9), na.rm=TRUE))
# q_lat<-matrix(quantile(z$X2, probs=c(0.05, 0.9), na.rm=TRUE))
# pres<-(which( q_lon[1,1]< z$X1 & z$X1<q_lon[2,1] & q_lat[1,1]< z$X2 & z$X2<q_lat[2,1]))
# z<-z[pres,]

latlon=data.frame(cbind(z$X1, z$X2))
names(latlon$X1)="lon"
names(latlon$X2)="lat"
coord=SpatialPoints(latlon)
plot(coord, col=z$Violation.Precinct, pch=18, cex=0.5, axes=TRUE)
dim(latlon)



object=SpatialPointsDataFrame(coords=latlon,data=data.frame(z$Violation.Precinct))

# obj is a list of all convex hulls. ch[[1]] has convex hull for precinct number 0, ch[[2]] for precinct 1 till ch[[35]] for precinct 34.

obj = list()
ch = list()
for(i in 0:(length(table(z$Violation.Precinct))-1))
  {
  obj[i+1]=SpatialPointsDataFrame(coords=coordinates(object[object$z.Violation.Precinct==i,]),data=data.frame(object[object$z.Violation.Precinct==i,]$z.Violation.Precinct))
  ch[i+1] = gConvexHull(obj[[i+1]])
  }



######## Now, the subsetted data is called "d"  Remove all else
#rm(d)
#rm(q_lon)
#rm(q_lat)
#rm(pres)

#pl = readOGR(paste0("/home/vis/cr173/Sta523/data/parking/pluto/Manhattan/"),"MNMapPLUTO")
#pt = gCentroid(pl,byid=TRUE)
#tax = cbind(data.frame(pt@coords), as.character(pl@data$Address))



#names=d$address[1:10000]
#n=length(names)
#object=rep(NA, n)
#for(i in 1:n){
#object[i]<-agrep(names[i], pluto$address[1001:2000], ignore.case = TRUE, value = FALSE,
#      max.distance = 5)
#}


#summary(object)

#pluto$address[10]
#names[1]
#pluto$address[373]
#names[2]
#pluto$address[75]
#names[3]


#precinct<-as.numeric(park$"Violation Location")
#address<-paste(park$"House Number", park$"Street Name")
#street<-park$"Street Name"
#cross<-park$"Intersecting Street"
#street<-str_trim(street, side = "right")
#cross<-str_trim(street, side = "left")
#streets<-paste(street,":",cross)



#Create a new dataframe with necessary variables
#d=data.frame("precinct"=as.numeric(precinct), 
#             "address"=address, 
#             "street"=street,
#             "cross"=cross,
#             "street"=street)



#Remove the original data frame and the temporary var names to save memory
#rm(house_street)
#rm(precinct)
#rm(address)
#rm(street)
#rm(cross)
#rm(park)




#library(dplyr)
#library(stringr)
#library(rgdal)
#library(rgeos)

# base = '/home/vis/cr173/Sta523/data/parking'
# 
# park = tbl_df(read.csv(paste0(base,"/NYParkingViolations_small.csv"), stringsAsFactors=FALSE))



## make the addresses in d (the original dataset) consistent
#E->EAST W->WEST
#Rd->ROAD
#AVE -> AVENUE
#AV->AVENUE
#ST-> STREET
#DR -> DRIVE
#PLWY
#PKWY->PARKWAY
#PLY
#BLVD -> BOULAVARD
#EXWY-> EXPRESSWAY
#PL ->PLACE
#TRD
#Get rid of "-" between numbers
#th, nd, st, rd


################ DO NOT RUN BELOW HERE ########################

# 
# 
# lat=lon=NULL
# names=d$address
# for(i in 1:length(names)) {
# if(pluto$address contain(names)
#   lat=pluto$X1
#   lon=pluto$X2
# 
#   lat=NA
# }
# 
# 
# 
# 
# 
# # Load 'ny borough' data
# basepath<-getwd()
# setwd("/home/vis/cr173/Sta523/data/parking/nybb")
# nyc<-readShapeSpatial("nybb")
# manhattan<-nyc[nyc$BoroName=="Manhattan",]
# setwd(basepath)
# rm(basepath)
# 
# 
# 
# man_int<-data.frame(man_int[,2])
# dir.create("data/", showWarnings = FALSE)
# save(d, file="data/d.csv")
# save(man_int, file="data/man_int.csv")
# 
# d[1:10,]
# length(unique(d[,2]))
# man_int[1:10,]
# length(unique(man_int$streets))
# 
# 
# names=d[,2]
# coord1=coord=rep(NA, length(names))
# 
# for(1 in 1:length(names)){
#   if (names==man_int$streets)
#      coord1<-man_int[,2] 
#      coord2<-man_int[,3]
#   }    
# 
# 
# 
# 
# # Load 'intersection' data to geocode
# basepath<-getwd()
# setwd("/home/vis/cr173/Sta523/data/parking/intersections")
# intersections<-readShapeSpatial("intersections")
# setwd(basepath)
# rm(basepath)
# 
# ### We could plot the map of Manhattan if we want
# # par(mar=c(2,2,1,1))
# # plot(nyc, axes=TRUE)
# # plot(manhattan, axes=TRUE)
# 
# ###### Since the intersection data has too many addresses, we subset the intersection data using the max and min of the longitude and lattitude of Manhattan.
# # 
# # minmax<-unlist(summary(manhattan)[2])
# # no=which(coordinates(intersections)[,1]>minmax[1] & 
# #          coordinates(intersections)[,1]<minmax[3] & 
# #          coordinates(intersections)[,2]>minmax[2] & 
# #          coordinates(intersections)[,2]<minmax[4] )
# # 
# # man_int=intersections[no,]  #observations in intersections data associated with manhattan addresses only
# 
# ## We could plot the coordinates of the remainder.
# # plot(man_int, axes=TRUE)
# 
# # Again, remove all the unnecessary temporary variable names.
# # rm(nyc)
# # rm(intersections)
# # rm(minmax)
# # rm(no)
# 
# 
# 
# 
# 
# ### we only work with address and precinct from now. rm all other data frame that takes up RAM space!
# ###geocode has 2500 requests limit a day
# 
# 
# # howmany <-1:100
# # howmany<-sample(1:length(address),2500,replace=FALSE)
# # howmany<-c(1:length(address))
# # 
# # latlon<-geocode(address[howmany], 
# #         output="latlon", 
# #         override_limit=FALSE) #geocode requires 'ggmap'
# # 
# # d<-cbind(latlon,precinct)
# # d[1:10,]
# # 
# # rm(address)
# # rm(precinct)
# # rm(howmany)
# 
# 

# 
# 
# 
# 
# ##### Plot the latitudes and longitudes in Manhattan
# 
# 
# ###### Save the objects as multipoints
# coord = SpatialPoints(data.frame(latlon)) 
# 
# 
# 
# ######## Recreating the boundary as GeoJson
# 
# 
# 
# 
# 
# 
# 
# 
# ######## Comparison
# 
# library(rgdal)
# 
# # To read GeoJSON must use OGRGeoJSON as layer
# p = readOGR("precinct_in.json","OGRGeoJSON") 
# 
# # Include precinct IDs as data with column named `precinct`
# p@data
# 
# 
# # Write to GeoJSON
# writeOGR(p, "./out", "", driver="GeoJSON") # Creates out file, current version of 
#                                            # GDAL does not allow . in file names 
#                                            # so we have to rename the file afterwards
# file.rename("./out", "./precinct.json")
# 
# p2 = readOGR("precinct.json","OGRGeoJSON") 
# 
# p2@data
# 
# 
# # Compare results
# pdf("plot.pdf",width=10,height=5)
# 
# par(mfrow=c(1,2))
# 
# # alpha affects alpha blending (makes things transparent), useful if polys may overlap
# plot(p,main = "precinct_in.json", axes=TRUE, col=adjustcolor(2:6,alpha=0.5))
# plot(p2,main = "precinct.json", axes=TRUE, col=adjustcolor(2:6,alpha=0.5))
# 
# # dev.off()

```



